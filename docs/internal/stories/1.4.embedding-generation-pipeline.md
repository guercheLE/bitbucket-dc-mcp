# Story 1.4: Embedding Generation Pipeline

## Status

Ready for Review

## Story

**As a** developer,  
**I want** script que gera embeddings para descriptions de operations Bitbucket usando modelo local (Transformers.js),  
**so that** posso implementar semantic search offline que encontra operations por natural language queries.

## Acceptance Criteria

1. Script `scripts/generate-embeddings.ts` lê `data/operations.json`
2. Para cada operation, cria description text concatenando: summary + description + operationId + common use case hints
3. Script usa Transformers.js com modelo local `Xenova/all-mpnet-base-v2` (768 dimensions) para gerar embeddings
4. Embeddings são salvos em formato intermediário `data/embeddings.json` (operationId + vector array)
5. Script implementa batching (processar múltiplas operations em chunks) para efficiency
6. Script tem progress indicator (console.log com % progress, ETA)
7. Script é configurável via env vars: `EMBEDDING_MODEL` (default: Xenova/all-mpnet-base-v2), `BATCH_SIZE`
8. Modelo é cached automaticamente no primeiro uso (~90MB download one-time)
9. Generated embeddings.json não é commitado no repo (gitignore), apenas em release artifacts

## Tasks / Subtasks

- [x] Task 1: Criar estrutura base do script (AC: 1, 7)
  - [x] Criar arquivo `scripts/generate-embeddings.ts`
  - [x] Configurar imports: @xenova/transformers, fs/promises para file I/O, zod para validation
  - [x] Definir interfaces TypeScript: `OperationData`, `EmbeddingResult`
  - [x] Implementar função `loadOperations(path: string): Promise<OperationData[]>` que lê `data/operations.json`
  - [x] Implementar função `loadEnvConfig()` com Zod validation schema (envSchema as shown in Dev Notes)
  - [x] Validar env vars: `EMBEDDING_MODEL` (default: Xenova/all-mpnet-base-v2), `BATCH_SIZE` (default: 32)
  - [x] Error handling: validar BATCH_SIZE > 0 e razoável (≤ 100) usando Zod .min(1).max(100)

- [x] Task 2: Implementar geração de description text (AC: 2)
  - [x] Criar função `generateDescriptionText(operation: OperationData): string`
  - [x] Concatenar campos com formato: `${summary} - ${description} [${operationId}]`
  - [x] Criar helper function `getUseCaseHint(method: HttpMethod, tags: string[]): string` para adicionar use case hints:
    ```typescript
    // Example: method=POST, tags=["Issues"] → hint: "This operation creates/adds a new resource"
    // Example: method=GET → hint: "This operation retrieves/fetches data"
    // Example: method=PUT/PATCH → hint: "This operation updates/modifies existing data"
    // Example: method=DELETE → hint: "This operation removes/deletes data"
    ```

  - [x] Normalizar texto: trim whitespace, remover line breaks duplos, max 8000 chars (model context limit)

- [x] Task 3: Implementar geração de embeddings com Transformers.js (AC: 3, 5)
  - [x] Criar função `generateEmbeddings(texts: string[], modelName: string): Promise<Float32Array[]>`
  - [x] Importar e inicializar pipeline: `import { pipeline } from '@xenova/transformers'`
  - [x] Criar extractor: `const extractor = await pipeline('feature-extraction', modelName)`
  - [x] Gerar embeddings: `const embeddings = await extractor(texts, { pooling: 'mean', normalize: true })`
  - [x] Processar em batches de BATCH_SIZE para controlar uso de memória
  - [x] Retornar embeddings como array de Float32Array (768 dimensions cada)
  - [x] Validar output: verificar que embeddings.length === texts.length e cada embedding tem 768 dimensions

- [x] Task 4: Implementar error handling - Model & Batch Level (AC: 8)
  - [x] Criar error handling para model loading failures (falta de memória, modelo corrompido)
  - [x] Implementar graceful degradation: se batch falhar, processar operations individualmente
  - [x] Log erros com contexto: qual operation causou erro, stack trace (use pino logger)
  - [x] Validar que modelo foi carregado corretamente antes de processar operations
  - [x] Verificar model caching behavior: primeiro uso faz download, subsequentes usam cache (~/.cache/huggingface/)

- [x] Task 5: Implementar progress indicator (AC: 7)
  - [x] Criar classe `ProgressTracker` com métodos: `start(total)`, `update(current)`, `finish()`
  - [x] Calcular e exibir: progress percentage, ETA (based on avg time per batch), current/total operations
  - [x] Format output: `[████████████░░░░] 75% (375/500 operations) ETA: 2m 30s`
  - [x] Update a cada batch processado (não a cada operation individual)
  - [x] Usar console.log para output (não logger - isto é user-facing CLI output)

- [x] Task 6: Implementar função main e salvar resultados (AC: 4, 8, 9)
  - [x] Criar função `main()` que orquestra o processo:
    1. Load config e validate env vars
    2. Inicializar modelo Transformers.js (download automático no primeiro uso - AC #8)
    3. Load operations.json
    4. Generate description texts para todas operations
    5. Dividir em batches (size configurável)
    6. Process cada batch com generateEmbeddings
    7. Agregar results em array de `EmbeddingResult[]`
    8. Save para `data/embeddings.json`
  - [x] Implementar função `saveEmbeddings(results: EmbeddingResult[], path: string): Promise<void>`
  - [x] Format output JSON com metadata: `{ model: 'Xenova/all-mpnet-base-v2', dimensions: 768, generated_at, embeddings: [...] }`
  - [x] Atualizar `.gitignore` para incluir `data/embeddings.json` (AC #9)
  - [x] Validar que embeddings.json não está sendo tracked pelo git após adicionar ao gitignore

- [x] Task 7: Implementar error handling - Script Orchestration Level
  - [x] Wrap main() em try/catch com structured logging (pino) de errors
  - [x] Validar que `data/operations.json` existe antes de processar (file system check)
  - [x] Handle parcial failures: se alguns batches falharem, salvar os que tiveram sucesso
  - [x] Log summary usando pino logger: operations processadas com sucesso, falhadas, tempo total
  - [x] Exit codes: 0 (success), 1 (complete failure), 2 (partial failure with some successes)
  - [x] Note: Use console.log ONLY for progress indicator (Task 5), all error/summary logging uses pino

- [x] Task 8: Adicionar unit tests (AC: coverage ≥80%)
  - [x] Criar `tests/unit/scripts/generate-embeddings.test.ts`
  - [x] Test `generateDescriptionText()`: valida format correto, use case hints, normalization
  - [x] Test `generateEmbeddings()` com mock Transformers.js:
    - Happy path: retorna embeddings corretos (768 dimensions)
    - Model loading: verifica que modelo é carregado corretamente
    - Batch processing: valida que batches são processados corretamente
    - Error handling: testa graceful degradation em falhas
  - [x] Test `ProgressTracker`: valida cálculos de progress e ETA
  - [x] Mock @xenova/transformers pipeline com vi.mock('@xenova/transformers')
  - [x] Coverage target: ≥85% line coverage

## Dev Notes

### Tech Stack
[Source: architecture/tech-stack.md]
- **Runtime:** Node.js 22+ LTS
- **Language:** TypeScript 5.x (strict mode)
- **Embeddings:** @xenova/transformers (latest)
- **Validation:** Zod 3.x para env var validation
- **Logging:** pino 8.x (structured JSON logs)
- **Testing:** Vitest (Jest-compatible API, native ESM)
- **Model:** Xenova/all-mpnet-base-v2 (768 dimensions)

**Model Details:**
- Model: Xenova/all-mpnet-base-v2 (sentence-transformers via ONNX)
- Dimensions: 768 (using Xenova/all-mpnet-base-v2 for local, air-gapped support)
- Download Size: ~90MB (one-time, cached em ~/.cache/huggingface/)
- Performance: ~80-150ms por embedding (CPU-only, acceptable)
- Quality: ~85-90% relevance (sufficient para domain-specific Bitbucket operations)
- Batch Processing: Recomendado 32 operations por batch para otimizar memória

### Project Structure
[Source: architecture/unified-project-structure.md]
```
scripts/
  ├── generate-embeddings.ts    # ESTE SCRIPT (build-time)
  ├── download-openapi.ts        # Produz operations.json (prerequisite)
  └── generate-schemas.ts        # Paralelo (não dependency)
data/
  ├── operations.json            # INPUT (gerado por 1.2)
  └── embeddings.json            # OUTPUT (este script, gitignored)
tests/unit/scripts/              # Tests espelham src/
```

**Key Architectural Decisions:**
- Build scripts em `scripts/` separados do runtime code (`src/`)
- `data/` é regenerável, embeddings.json não é commitado (apenas release artifacts)
- Scripts usam console.log para progress (user-facing), pino logger para structured logs

### Data Models
[Source: architecture/data-models.md]

**Input: OperationData (de operations.json)**
```typescript
interface OperationData {
  operation_id: string;       // Ex: "create_issue"
  path: string;               // Ex: "/rest/api/3/issue"
  method: HttpMethod;         // "GET" | "POST" | "PUT" | "DELETE"
  summary: string;            // Descrição breve
  description: string;        // Descrição detalhada
  tags: string[];            // Ex: ["Issues", "Projects"]
  parameters: Parameter[];
  requestBody: RequestBody | null;
  responses: Record<string, Response>;
}
```

**Output: EmbeddingResult (para embeddings.json)**
```typescript
interface EmbeddingResult {
  operation_id: string;
  vector: number[];          // Array de 768 floats (Xenova/all-mpnet-base-v2)
  model: string;             // "Xenova/all-mpnet-base-v2"
  description_text: string;  // O texto usado para gerar embedding
  created_at: string;        // ISO timestamp
}

interface EmbeddingsFile {
  model: string;
  generated_at: string;
  embedding_dimensions: number;  // 768 (using local Transformers.js model)
  total_operations: number;
  embeddings: EmbeddingResult[];
}
```

### Coding Standards
[Source: architecture/coding-standards.md]
- **Type Safety:** TypeScript strict mode, no `any` types (use `unknown` e narrow com type guards)
- **Error Handling:** Sempre try/catch em async functions, nunca swallow errors
- **Async/Await:** Sempre async/await, não usar `.then()/.catch()` chains
- **No Console.log para logs:** Usar pino Logger para structured logs. **EXCEPTION:** Console.log is ONLY acceptable in build scripts (scripts/) for user-facing progress indicators - not for application logging in src/
- **Input Validation:** Validar env vars com Zod schemas
- **Immutability:** Prefer const, não mutar arrays/objects
- **Constants:** No magic numbers, usar constants: `const MAX_RETRIES = 3`, `const DEFAULT_BATCH_SIZE = 100`
- **Documentation:** TSDoc comments para public functions

**Naming Conventions:**
- Functions: camelCase (`generateEmbeddings`)
- Constants: UPPER_SNAKE_CASE (`MAX_RETRIES`, `DEFAULT_BATCH_SIZE`)
- Files: kebab-case (`generate-embeddings.ts`)
- Interfaces: PascalCase (`OperationData`, `EmbeddingResult`)

### Testing
[Source: architecture/testing-strategy.md]

**Test File Location:** `tests/unit/scripts/generate-embeddings.test.ts`

**Testing Framework:**
- Vitest (Jest-compatible API)
- Mocking: `vi.mock()`, `vi.fn()`
- Coverage Target: ≥85% line coverage

**Test Structure Example:**
```typescript
import { describe, it, expect, beforeEach, vi } from 'vitest';
import { generateDescriptionText, generateEmbeddings } from '../../../scripts/generate-embeddings.js';

describe('generateDescriptionText', () => {
  it('should concatenate summary, description, and operationId', () => {
    const operation = {
      operation_id: 'create_issue',
      summary: 'Create issue',
      description: 'Creates a new issue in Bitbucket',
      method: 'POST',
      tags: ['Issues']
    };
    
    const result = generateDescriptionText(operation);
    
    expect(result).toContain('Create issue');
    expect(result).toContain('Creates a new issue');
    expect(result).toContain('[create_issue]');
  });
  
  it('should add use case hints based on HTTP method', () => {
    const operation = { method: 'POST', summary: 'Test', description: 'Test', operation_id: 'test' };
    const result = generateDescriptionText(operation);
    expect(result).toContain('creates/adds');
  });
});

describe('generateEmbeddings with mocked Transformers.js', () => {
  beforeEach(() => {
    vi.mock('@xenova/transformers');
  });
  
  it('should generate embeddings with correct dimensions', async () => {
    // Mock pipeline
    const mockExtractor = vi.fn().mockResolvedValue({
      data: [new Float32Array(768).fill(0.1)]
    });
    
    const mockPipeline = vi.fn().mockResolvedValue(mockExtractor);
    vi.mocked(pipeline).mockImplementation(mockPipeline);
    
    const result = await generateEmbeddings(['test text'], 'Xenova/all-mpnet-base-v2');
    
    expect(result).toHaveLength(1);
    expect(result[0]).toHaveLength(768);
    expect(mockPipeline).toHaveBeenCalledWith('feature-extraction', 'Xenova/all-mpnet-base-v2');
  });
});
```

**Key Test Cases:**
1. Description text generation (format, use case hints)
2. Transformers.js embeddings generation (768 dimensions, batch processing)
3. Model loading and initialization
4. Progress tracking (calculations, display)
5. Error handling (missing files, model loading failures, partial failures)

### Local Model Integration
[Source: architecture/tech-stack.md]

**Transformers.js Integration:**
- Library: @xenova/transformers (Hugging Face Transformers para Node.js)
- Model: Xenova/all-mpnet-base-v2 (sentence-transformers via ONNX)
- No external API calls: 100% local, air-gapped compatible

**Usage Pattern:**
```typescript
import { pipeline } from '@xenova/transformers';

// Inicializar pipeline (download automático do modelo no primeiro uso)
const extractor = await pipeline('feature-extraction', 'Xenova/all-mpnet-base-v2');

// Gerar embeddings
const output = await extractor(texts, { 
  pooling: 'mean',  // Mean pooling dos tokens
  normalize: true   // Normalizar vetores para cosine similarity
});

// Resultado: { data: Float32Array[] } com 768 dimensions cada
```

**Performance Characteristics:**
- First run: ~5-10s (download modelo 90MB)
- Subsequent runs: ~80-150ms por embedding (modelo cached)
- Memory usage: ~200-300MB com modelo carregado
- CPU-only: Sem GPU acceleration em v1.0

**Integration Notes:**
- Build-time: Script gera embeddings dataset uma vez
- Runtime: SemanticSearchService usa mesmo modelo para query embeddings
- Caching: Modelo cached em `~/.cache/huggingface/` automaticamente
- Cross-platform: Funciona em Linux/macOS/Windows sem binários específicos

### Environment Variables
**Optional (todas têm defaults):**
- `EMBEDDING_MODEL` - Modelo a usar (default: `Xenova/all-mpnet-base-v2`)
- `BATCH_SIZE` - Operations por batch (default: `32`, recommended: `16-64`)

**Validation com Zod:**
```typescript
const envSchema = z.object({
  EMBEDDING_MODEL: z.string().default('Xenova/all-mpnet-base-v2'),
  BATCH_SIZE: z.coerce.number().min(1).max(100).default(32)
});
```

### Dependencies para Adicionar
```json
{
  "dependencies": {
    "@xenova/transformers": "^2.x",  // Local embeddings generation
    "zod": "^3.x"                    // Validation (já instalado em 1.3)
  },
  "devDependencies": {
    "@types/node": "^18.x",
    "vitest": "latest"               // Testing (já instalado em 1.1)
  }
}
```

### Script Execution
**Comando:**
```bash
npm run generate-embeddings
```

**Package.json script:**
```json
{
  "scripts": {
    "generate-embeddings": "tsx scripts/generate-embeddings.ts"
  }
}
```

**Expected Output:**
```
Loading operations from data/operations.json...
Loaded 523 operations

Initializing Transformers.js model: Xenova/all-mpnet-base-v2
Model loaded successfully (cached: true)

Generating embeddings...
Batch size: 32 operations

[████████████████████] 100% (523/523 operations) Completed in 2m 15s

Embeddings saved to data/embeddings.json
  Model: Xenova/all-mpnet-base-v2
  Dimensions: 768
  Total operations: 523
  File size: 1.8 MB
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-15 | 1.0 | Initial story creation for Epic 1.4 | Bob (Scrum Master) |
| 2025-01-15 | 1.1 | Story approved after validation checklist passed | Bob (Scrum Master) |
| 2025-10-16 | 1.2 | Validation passed: Fixed embedding dimensions (768 not 1536), clarified console.log exception for build scripts, improved AC mapping to tasks, consolidated error handling tasks, added Zod validation details. Story re-approved and ready for implementation. | Sarah (Product Owner) |
| 2025-10-16 | 1.3 | Re-validation completed: All 9 ACs properly mapped, Transformers.js integration validated (768 dimensions confirmed), batch processing strategy verified, error handling robust, Zod env validation confirmed. Implementation Readiness Score: 10/10. Status: APPROVED | GitHub Copilot (AI Assistant) |
| 2025-10-17 | 1.4 | Implemented embeddings pipeline script, progress tracking, structured logging, gitignore update, and unit tests. Status moved to Ready for Review. | James (Developer) |

## Dev Agent Record

### Agent Model Used

- GPT-5-Codex

### Debug Log References

- `npm install`
- `npx eslint scripts/generate-embeddings.ts tests/unit/scripts/generate-embeddings.test.ts`
- `npm test`

### Completion Notes List

- Implemented embeddings pipeline script with batching, fallback handling, and structured logging via pino.
- Added progress tracker and env validation using Zod defaults for model and batch size.
- Persist embeddings metadata to `data/embeddings.json` and ensured artifact is ignored by git.
- Created comprehensive unit tests mocking Transformers.js to cover description generation, batching, and progress tracking flows.

### File List

- scripts/generate-embeddings.ts (new)
- tests/unit/scripts/generate-embeddings.test.ts (new)
- package.json (modified)
- package-lock.json (modified)
- .gitignore (modified)

## QA Results

_This section will be populated by QA Agent after story implementation is complete._

